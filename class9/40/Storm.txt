一、Storm概述
	网址：http://storm.apache.org/
	Apache Storm是一个免费的开源分布式实时计算系统。Storm可以轻松可靠地处理无限数据流，实
	现Hadoop对批处理所做的实时处理。Storm非常简单，可以与任何编程语言一起使用，并且使用起
	来很有趣！
	Storm有许多用例：实时分析，在线机器学习，连续计算，分布式RPC，ETL等。风暴很快：一个基
	准测试表示每个节点每秒处理超过一百万个元组。它具有可扩展性，容错性，可确保您的数据得到处
	理，并且易于设置和操作。
	Storm集成了您已经使用的排队和数据库技术。Storm拓扑消耗数据流并以任意复杂的方式处理这些
	流，然后在计算的每个阶段之间重新划分流。阅读教程中的更多内容。
	
	离线计算是什么？
	批量获取数据、批量的传输数据、批量的存储数据、周期性计算数据、数据可视化
	flume批量获取数据、sqoop批量传输、hdfs/hive/hbase批量存储、mr/hive计算数据、BI
	
	实时计算是什么？
	数据实时产生、数据实时传输、数据实时计算、实时展示
	flume实时获取数据、kafka实时数据存储、Storm/JStorm实时计算、实时展示(dataV/quickBI)
	
二、Storm与Hadoop
	          hadoop       		   storm
	角色：   JobTracker    		 Nimbus
	         TaskTracker   		 Supervisor
	         Child         		 Worker
	应用名称：Job        		 Topology
	编程接口：Mapper/Reducer 	 Spout/Bolt
	
三、storm编程模型
	tuple:元组
	是消息传输的基本单元。
	
	Spout:水龙头
	storm的核心抽象。拓扑的流的来源。Spout通常从外部数据源读取数据。转换为拓扑内部的源数据。
	主要方法：nextTuple() -》 发出一个新的元祖到拓扑。
	ack()
	fail()
	
	Bolt:转接头
	Bolt是对流的处理节点。Bolt作用：过滤、业务、连接运算。
	
	Topology:拓扑
	是一个实时的应用程序。
	永远运行除非被杀死。
	Spout到Bolt是一个连接流...
	
	wordcount
	spark->wordcount
	storm流式计算
	hadoop与storm兼容性
	spark-core
	spark-sql离线计算
	spark-streaming流式计算
	一个团队开发
	没有兼容性问题
	spark团队：我要做一栈式开发平台！
	但凡涉及到大数据计算 我都能搞定！
	spark替代了mapreduce
	spark没有底层存储
	依赖hdfs
	hdfs/mr............
	完善整个生态圈系统！
	mapreduce思想、编程 、sqoop->mr hive->mr hbasemr
	dfs/mapreduce/bigtable
	java/scala...
	
四、Storm集群安装部署
	1）准备工作
	zk01 zk02 zk03
	storm01 storm02 storm03
	
	2)下载安装包
	http://storm.apache.org/downloads.html
	
	3)上传apache-storm-1.1.0.tar.gz到/root下
	
	4)解压
	cd /root
	tar -zxvf apache-storm-1.1.0.tar.gz -C /root/hd/
	
	5)修改配置文件
	cd /root/hd
	mv apache-storm-1.1.0/ storm
	cd storm/conf/
	$ vi storm.yaml
	# 设置Zookeeper的主机名称
	storm.zookeeper.servers:
	- "hd09-1"
	- "hd09-2"
	- "hd09-3"

	# 设置主节点的主机名称
	nimbus.seeds: ["hd09-1"]
	# 设置Storm的数据存储路径
	storm.local.dir: "/root/hd/storm/data"
	# 设置Worker的端口号
	supervisor.slots.ports:
	- 6700
	- 6701
	- 6702
	- 6703
	
	6)创建文件夹/root/hd/storm/data
	mkdir /root/hd/storm/data
	
	7)配置环境变量
	vi /etc/profile
	在最下面加入
	export STORM_HOME=/root/hd/storm
	export PATH=$PATH:$STORM_HOME/bin
	
	生效环境变量
	source /etc/profile
	
	8)分发安装包到其他机器
	cd /root/hd/
	scp -r storm/ hd09-2:$PWD
	scp -r storm/ hd09-3:$PWD
	
	9)启动Zookeeper
	zkServer.sh start（三台机器都执行）
	
	10)启动nimbus
	storm nimbus & （三台机器都执行）
	
	11) 启动supervisor
	storm supervisor & （三台机器都执行）
	
	12)启动ui界面
	storm ui
	浏览器输入http://192.168.146.132:8080可以访问

五、Storm命令行操作
	1)查看命令帮助
	storm help
	
	2)查看版本
	storm version
	
	3)运行storm程序
	storm jar [/路径/.jar][全类名][拓扑名称]
	
	4）查看当前正在运行拓扑及其状态
	storm list
	
	5)终止拓扑程序
	storm kill [拓扑名称]
	
	6）激活拓扑程序
	storm activate [拓扑名称]
	
	7）禁止拓扑程序
	storm deactivate [拓扑名称]

六、分组策略
	1）Fields Grouping
	按照字段分组。相同字段发送到一个task中。
	
	2）shuffle Grouping
	随机分组。轮询。平均分配。随机分发tuple，保证每个bolt中的tuple数量相同。
	
	3）Non Grouping
	不分组
	采用这种策略每个bolt中接收的单词不同。
	
	4）All Grouping
	广播发送
	
	5）Global Grouping
	全局分组	
	分配给task id值最小的
	根据线程id判断，只分配给线程id最小的





