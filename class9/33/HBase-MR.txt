官方HBase-Mapreduce
需求1：对一张表的rowkey进行计数
	1）导入环境变量
	export HBASE_HOME=/root/hd/hbase-1.3.0
	export HADOOP_HOME=/root/hd/hadoop-2.8.4
	export HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase mapredcp`
	可以添加到：hbase-env.sh
	
	2）启动HBase-mr任务
	cd /root/hd/hbase-1.3.0
	/root/hd/hadoop-2.8.4/bin/yarn jar lib/hbase-server-1.3.0.jar rowcounter emp
	
需求2：本地数据导入到HBase中
	思路？HBase底层存储是hdfs,把数据先导入到hdfs
	HBase对应创建一张表
	利用mr导入数据到表中
	
	1）在hdfs中创建文件夹 导入本地数据	
	hdfs dfs -mkdir /lovein
	hdfs dfs -put /root/love.tsv /lovein
	
	2）创建表
	create 'love','info'
	
	3）导入操作
	cd /root/hd/hbase-1.3.0
	/root/hd/hadoop-2.8.4/bin/yarn jar lib/hbase-server-1.3.0.jar importtsv -Dimporttsv.columns=HBASE_ROW_KEY,info:name,info:description love hdfs://hd09-1:9000/lovein/

自定义HBase-mr	
需求3：将HBase中love表进行指定列的筛选然后倒入到lovemr表
	1）构建Mapper类，读取love表中数据
	2）构建Reducer类，将love表中数据写入到lovemr表中
	3）构建driver驱动类
	4） 打包 放入集群中运行这个任务

	5）创建表
	create 'lovemr','info'
	
	6）导入操作	
	进入到HbaseTest-1.0-SNAPSHOT.jar包所在目录
	/root/hd/hadoop-2.8.4/bin/yarn jar HbaseTest-1.0-SNAPSHOT.jar com.hbase.mr.LoveDriver

需求4：HDFS中的数据写入到HBase中
	思路：
    1）构建Mapper 来读取hdfs中的数据
    2）构建Reducer
    3）驱动类
    4）打包运行
    5）测试	
	
	6）在hdfs中创建文件夹 导入本地数据	
	hdfs dfs -mkdir /lovehbase
	hdfs dfs -put /root/love.tsv /lovehabse
	
	7）创建表
	create 'lovehdfs','info'

	8）写入操作	
	进入到HbaseTest-1.0-SNAPSHOT.jar包所在目录
	/root/hd/hadoop-2.8.4/bin/yarn jar HbaseTest-1.0-SNAPSHOT.jar com.hbase.mr2.LoveDriver

	
	
