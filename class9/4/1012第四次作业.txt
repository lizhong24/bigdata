1.HDFS集群修改SecondaryNameNode位置到hd09-2
    （1）修改hdfs-site.xml
		<configuration>
			//配置元数据存储位置
			<property>
				<name>dfs.namenode.name.dir</name>
				<value>/root/hd/dfs/name</value>
			</property>
			//配置数据存储位置
			<property>
				<name>dfs.datanode.data.dir</name>
				<value>/root/hd/dfs/data</value>
			</property>
			
			<property>
				<name>dfs.namenode.secondary.http-address</name>
				<value>hd09-2:50090</value>
			</property>	
		</configuration>
		
		注意上面的第三个<property>不是
			<property>
				<name>dfs.namenode.secondary.https-address</name>
				<value>hd09-2:50090</value>
			</property>	
		
	（2）分发hdfs-site.xml到其他服务器
		cd /root/hd/hadoop-2.8.4/etc/hadoop
		
		scp hdfs-site.xml hd09-2:$PWD
		scp hdfs-site.xml hd09-3:$PWD
	
	（3）hdfs启动命令
		start-dfs.sh
	
	（4）hdfs停止命令
		stop-dfs.sh

2.HDFS集群修改replication（副本数）
		修改hdfs-site.xml 在<configuration>中加入
			<property>
				<name>dfs.replication</name>
				<value>3</value>
			</property>
		其中<value>中的值就是副本数

3.HDFS集群修改blocksize（块大小）				
		修改hdfs-site.xml 在<configuration>中加入
			<property>
				<name>dfs.blocksize</name>
				<value>134217728</value>
			</property>
		其中<value>中的值就是块大小，单位是字节(byte)
		
4.hdfs命令行
	（1）查看帮助
		hdfs dfs -help 
		
	（2）查看当前目录信息
		hdfs dfs -ls /
		
	（3）上传文件
		hdfs dfs -put /本地路径 /hdfs路径
		
	（4）剪切文件
		hdfs dfs -moveFromLocal a.txt /aa.txt
		
	（5）下载文件到本地
		hdfs dfs -get /hdfs路径 /本地路径
		
	（6）合并下载
		hdfs dfs -getmerge /hdfs路径文件夹 /合并后的文件
		
	（7）创建文件夹
		hdfs dfs -mkdir /hello
		
	（8）创建多级文件夹
		hdfs dfs -mkdir -p /hello/world
		
	（9）移动hdfs文件
		hdfs dfs -mv /hdfs路径 /hdfs路径
		
	（10）复制hdfs文件
		hdfs dfs -cp /hdfs路径 /hdfs路径
		
	（11）删除hdfs文件
		hdfs dfs -rm /aa.txt
		
	（12）删除hdfs文件夹
		hdfs dfs -rm -r /hello
		
	（13）查看hdfs中的文件
		hdfs dfs -cat /文件
		hdfs dfs -tail -f /文件
		
	（14）查看文件夹中有多少个文件
		hdfs dfs -count /文件夹
		
	（15）查看hdfs的总空间
		hdfs dfs -df /
		hdfs dfs -df -h /
		
	（16）修改副本数	
		hdfs dfs -setrep 1 /a.txt
	

